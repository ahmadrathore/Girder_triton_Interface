{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Fetched 336 kB in 3s (127 kB/s)                                     \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "openslide-tools is already the newest version (3.4.1+dfsg-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 91 not upgraded.\n",
      "Requirement already satisfied: openslide-python in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from openslide-python) (9.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in links: https://girder.github.io/large_image_wheels\n",
      "Requirement already satisfied: histomics_stream in /usr/local/lib/python3.8/dist-packages (2.2.4)\n",
      "Requirement already satisfied: large_image[openslide] in /usr/local/lib/python3.8/dist-packages (1.17.2)\n",
      "Requirement already satisfied: scikit_image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n",
      "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.8/dist-packages (from histomics_stream) (2022.9.26)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from histomics_stream) (1.22.4)\n",
      "Requirement already satisfied: itk in /usr/local/lib/python3.8/dist-packages (from histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: zarr in /usr/local/lib/python3.8/dist-packages (from histomics_stream) (2.13.3)\n",
      "Requirement already satisfied: psutil>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from large_image[openslide]) (5.9.1)\n",
      "Requirement already satisfied: palettable in /usr/local/lib/python3.8/dist-packages (from large_image[openslide]) (3.3.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from large_image[openslide]) (9.1.1)\n",
      "Requirement already satisfied: cachetools>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from large_image[openslide]) (5.1.0)\n",
      "Requirement already satisfied: large-image-source-openslide>=1.17.2; extra == \"openslide\" in /usr/local/lib/python3.8/dist-packages (from large_image[openslide]) (1.17.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (21.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (1.9.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (2.8.7)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (2.22.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit_image) (2022.10.10)\n",
      "Requirement already satisfied: itk-registration==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: itk-core==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: itk-segmentation==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: itk-filtering==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: itk-numerics==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: itk-io==5.2.1.post1 in /usr/local/lib/python3.8/dist-packages (from itk->histomics_stream) (5.2.1.post1)\n",
      "Requirement already satisfied: asciitree in /usr/local/lib/python3.8/dist-packages (from zarr->histomics_stream) (0.3.3)\n",
      "Requirement already satisfied: numcodecs>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from zarr->histomics_stream) (0.10.2)\n",
      "Requirement already satisfied: fasteners in /usr/local/lib/python3.8/dist-packages (from zarr->histomics_stream) (0.18)\n",
      "Requirement already satisfied: openslide-python>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from large-image-source-openslide>=1.17.2; extra == \"openslide\"->large_image[openslide]) (1.2.0)\n",
      "Requirement already satisfied: tifftools>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from large-image-source-openslide>=1.17.2; extra == \"openslide\"->large_image[openslide]) (1.3.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit_image) (3.0.9)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from numcodecs>=0.10.0->zarr->histomics_stream) (0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from numcodecs>=0.10.0->zarr->histomics_stream) (4.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: mil[ray] from git+https://ahmadrathore:****@github.com/PathologyDataScience/mil.git@dev#egg=mil[ray] in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mil[ray]) (1.22.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mil[ray]) (1.5.0)\n",
      "Requirement already satisfied: tensorflow>=2.6 in /usr/local/lib/python3.8/dist-packages (from mil[ray]) (2.9.1)\n",
      "Requirement already satisfied: ray[tune]; extra == \"ray\" in /usr/local/lib/python3.8/dist-packages (from mil[ray]) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->mil[ray]) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->mil[ray]) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.41.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.12)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (0.26.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (3.19.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (4.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.6->mil[ray]) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (62.3.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6->mil[ray]) (3.6.0)\n",
      "Requirement already satisfied: virtualenv in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (20.16.5)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (4.5.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (1.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (3.8.0)\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (8.0.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (6.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (21.4.0)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (1.2.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (1.0.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (2.22.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9; extra == \"tune\" in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (2.5.1)\n",
      "Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.8/dist-packages (from ray[tune]; extra == \"ray\"->mil[ray]) (0.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6->mil[ray]) (0.34.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.6->mil[ray]) (3.0.9)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (2.6.6)\n",
      "Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from virtualenv->ray[tune]; extra == \"ray\"->mil[ray]) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv->ray[tune]; extra == \"ray\"->mil[ray]) (2.5.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]; extra == \"ray\"->mil[ray]) (5.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]; extra == \"ray\"->mil[ray]) (0.18.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (4.11.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (0.2.8)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema->ray[tune]; extra == \"ray\"->mil[ray]) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->mil[ray]) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install openslide, histomics_stream, pandas\n",
    "!apt-get update\n",
    "!apt-get install -y openslide-tools\n",
    "!pip install openslide-python\n",
    "!pip install histomics_stream 'large_image[openslide]' scikit_image --find-links https://girder.github.io/large_image_wheels\n",
    "!pip install pandas\n",
    "\n",
    "# install mil library with extra ray[tune]\n",
    "user = 'ahmadrathore' #git username\n",
    "token = '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' #personal access token - see https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n",
    "branch = 'dev'\n",
    "!python -m pip install git+https://{user}:{token}@github.com/PathologyDataScience/mil.git@{branch}#egg=mil[ray]\n",
    "        \n",
    "# imports\n",
    "from mil.metrics import Balanced, F1, Mcc, Sensitivity, Specificity\n",
    "from mil.models import convolutional_model, attention_flat, attention_flat_tune\n",
    "from mil.io.reader import read_record, peek\n",
    "from mil.io.transforms import parallel_dataset\n",
    "from mil.io.utils import inference, study\n",
    "from mil.io.writer import write_record\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction parameters\n",
    "\n",
    "Feature extraction parameters have a significant impact on model performance, both in terms of accuracy and the time it takes to train a model. Here, we specify the magnification used to extract features, the size of tiles that features are extracted from, the overlap between these tiles, and the number of tiles contained within each read (chunk). We specify a pre-trained model to use for feature extraction, as well as a set of whole-slide images. A large overlap ensures that important structures will appear whole in at least some tiles, but will significantly increase the amount of data that is saved and subsequently used in training.\n",
    "\n",
    "Parameters are also required for saving the features in .tfr files. We have to define the names of the subject labels stored in the .tfr, and the location to save these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction parameters\n",
    "t=224 # tile size (pixels)\n",
    "overlap=0 # tile overlap (pixels)\n",
    "chunk=1792 # chunk size (pixels)\n",
    "magnification=20 # magnification\n",
    "tile_batch=128 # the number of tiles to batch\n",
    "tile_prefetch=2 # the number of batches to prefetch\n",
    "elapsed=0\n",
    "model_name='EfficientNetV2L' # the pre-trained model for feature extraction\n",
    "svspath = '/tf/notebooks/Course-ece495/train/' # path for the whole-slide images\n",
    "outpath = svspath\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and wrapping the feature extraction model\n",
    "\n",
    "To use HistomicsStream for feature extraction, we have to wrap the feature extraction model so that the tile location information and other metadata can be passed through the model and captured at the output registered to the features. HistomicsStream is used to generate a tf.data.Dataset of tiles, and features are extracted from this using tf.keras.Model.predict. Since predict takes a single input, we combine (tiles, tile_metadata) for passing to the wrapped model. Inside the wrapper these are separated and inference is done on the tiles. Wrapping is necessary to avoid having the tile_metadata discarded. We also add a dummy 'y' variable 0. to be discarded by predict.\n",
    "\n",
    "To enable multi-GPU feature extraction, the feature extraction model is loaded outside the parallel context, and is wrapped inside the parallel context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "# define the wrapped model class\n",
    "class WrappedModel(tf.keras.Model):\n",
    "    def __init__(self, extractor, *args, **kwargs):\n",
    "        super(WrappedModel, self).__init__(*args, **kwargs)\n",
    "        self.model = extractor\n",
    "        \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return self.model(inputs[0]), inputs[1]\n",
    "    \n",
    "\n",
    "# create the feature extractor model to be wrapped\n",
    "model = tf.keras.applications.efficientnet_v2.EfficientNetV2L(\n",
    "        include_top=False, weights='imagenet', input_shape=(t, t, 3),\n",
    "        pooling='avg')\n",
    "\n",
    "# get dimensionality of extracted features\n",
    "D = model.output_shape[-1]\n",
    "\n",
    "# create a distributed wrapped model\n",
    "with tf.distribute.MirroredStrategy().scope():\n",
    "    \n",
    "    # wrap the model\n",
    "    wrapped_model = WrappedModel(model, name='wrapped_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect a .tfr file\n",
    "\n",
    "`mil.io.reader.peek` inspects the contents of a .tfr file and returns a dictionary of the variable names and types. This can be helpful to inspect datasets and determine the user metadata embedded in the .tfr files.\n",
    "\n",
    "Due to the way tensorflow handles loading .tfr files, this information cannot be acquired at runtime, and so we capture it here in eager mode and provide it to `mil.io.reader.read_record` when training the networks in graph mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Put the files in cache memory for fast access\n",
    "def files_cache(s, pat=re.compile('100%')):\n",
    "    if pat.search(s):\n",
    "        print(\"Files already in Cache Memory\")\n",
    "    else:\n",
    "        print(\"Adding Files in Cache Memory\")\n",
    "        subprocess.check_output(['vmtouch','-t',npy_files_path])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already in Cache Memory\n",
      "417\n",
      "Total read Time: ~123.26394438743591 second\n",
      "Average Throughput: ~3.3829843923322 examples / second\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "outpath = svspath\n",
    "# get list of created tf.records\n",
    "\n",
    "files = [outpath + file for file in os.listdir(outpath) if os.path.splitext(file)[1] == '.tfr']\n",
    "\n",
    "tfr_files_path = outpath\n",
    "result= subprocess.check_output(['vmtouch',tfr_files_path])\n",
    "files_cache(str(result))\n",
    "\n",
    "i = 0\n",
    "for filename in files:\n",
    "    i+=1\n",
    "print(\"Number of .tfr files\",i)\n",
    "start_time = time.time()\n",
    "\n",
    "# iterate over files in that directory\n",
    "for filename in files:\n",
    "    serialized = list(tf.data.TFRecordDataset(filename))[0]\n",
    "    variables = peek(serialized)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Total read Time: ~{} second'.format((end_time - start_time)))\n",
    "print('Average Throughput: ~{} examples / second'.format(i/ (end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"label_site\": \"bytes_list\",\n",
      "  \"label_time\": \"int64_list\",\n",
      "  \"label_dataset\": \"bytes_list\",\n",
      "  \"label_histology\": \"bytes_list\",\n",
      "  \"label_subject\": \"bytes_list\",\n",
      "  \"number_pixel_columns_for_slide\": \"int64_list\",\n",
      "  \"label_grade\": \"float_list\",\n",
      "  \"scan_magnification\": \"float_list\",\n",
      "  \"number_tile_columns_for_slide\": \"int64_list\",\n",
      "  \"tf_version\": \"bytes_list\",\n",
      "  \"tile_top\": \"int64_list\",\n",
      "  \"histomics_version\": \"bytes_list\",\n",
      "  \"slide_group\": \"bytes_list\",\n",
      "  \"created\": \"bytes_list\",\n",
      "  \"label_subtype\": \"bytes_list\",\n",
      "  \"chunk_top\": \"int64_list\",\n",
      "  \"level\": \"int64_list\",\n",
      "  \"label_gender\": \"bytes_list\",\n",
      "  \"filename\": \"bytes_list\",\n",
      "  \"number_tile_rows_for_slide\": \"int64_list\",\n",
      "  \"slide_index\": \"int64_list\",\n",
      "  \"number_pixel_columns_for_chunk\": \"int64_list\",\n",
      "  \"number_pixel_rows_for_slide\": \"int64_list\",\n",
      "  \"features\": \"float_list\",\n",
      "  \"chunk_left\": \"int64_list\",\n",
      "  \"read_magnification\": \"float_list\",\n",
      "  \"label_event\": \"bytes_list\",\n",
      "  \"label_age\": \"float_list\",\n",
      "  \"number_pixel_rows_for_chunk\": \"int64_list\",\n",
      "  \"number_pixel_rows_for_tile\": \"int64_list\",\n",
      "  \"shape\": \"int64_list\",\n",
      "  \"number_pixel_columns_for_tile\": \"int64_list\",\n",
      "  \"returned_magnification\": \"float_list\",\n",
      "  \"slide_name\": \"bytes_list\",\n",
      "  \"tile_left\": \"int64_list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# display variables\n",
    "print(json.dumps(variables, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional model from structured tensors\n",
    "\n",
    "Here we use the `mil.models` subpackage to build and train a simple convolutional model for the structured tensor. This model uses weighted-average pooling (attention) to pool the convolutional feature maps over the entire image to make a prediction. This enables support for variable-sized images.\n",
    "\n",
    "We use the `mil.io.reader.read_record` function with a `tf.data.Dataset` to read features in structured format. Interpreting the .tfr requires passing in the label names were stored within the file. When we load the data, we pick a single label and threshold that to form a binary classificaiton problem (the original labels range from 0 to 4).\n",
    "\n",
    "We also use several new metrics from the `tf.metrics` subpackage to monitor performance during training. These metrics were implemented to address the specific issues of validating pathology models, and are not available in the TensorFlow core package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# create a list of metrics to monitor performance during training\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
    "           tf.keras.metrics.AUC(curve='ROC'),\n",
    "           Balanced(threshold=0.5),\n",
    "           F1(threshold=0.5),\n",
    "           Mcc(threshold=0.5),\n",
    "           Sensitivity(threshold=0.5),\n",
    "           Specificity(threshold=0.5)]\n",
    "\n",
    "# create and compile model\n",
    "model = convolutional_model(D)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss={'softmax': tf.keras.losses.BinaryCrossentropy()},\n",
    "              metrics={'softmax': metrics})\n",
    "\n",
    "#define label function for training dataset\n",
    "def threshold(value, key='t', cond=lambda x: x>=2.0):\n",
    "    return tf.one_hot(tf.cast(cond(value[key]), tf.int32), depth=2)\n",
    "\n",
    "# build dataset and train\n",
    "train_ds = tf.data.TFRecordDataset(files, num_parallel_reads=4).shuffle(len(files))\n",
    "train_ds = train_ds.map(lambda x: read_record(x, variables, structured=True))\n",
    "train_ds = train_ds.map(lambda x, y, z, _: (x, threshold(y, 't')[0]))\n",
    "train_ds = train_ds.batch(1).prefetch(2)\n",
    "\n",
    "# train model\n",
    "start_time = time.time()\n",
    "model.fit(train_ds, batch_size=1, epochs=5)\n",
    "end_time = time.time()\n",
    "print('Time: ~{} second'.format((end_time - start_time)))\n",
    "print('Average Throughput: ~{} examples / second'.format(1 * 1 / (end_time - start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a set-based model from flattened tensors\n",
    "\n",
    "Although the tensors are stored in a structured format, they can also be read in a flattened format using *io.read_record* with structured=False.\n",
    "\n",
    "The *models* subpackage also contains set-based models with dense layers that process each tile independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build and compile model\n",
    "# model = attention_flat(D)\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "#               loss={'softmax': tf.keras.losses.BinaryCrossentropy()},\n",
    "#               metrics={'softmax': metrics})\n",
    "\n",
    "# # build dataset and train\n",
    "# train_ds = tf.data.TFRecordDataset(files, num_parallel_reads=4).shuffle(len(files))\n",
    "# train_ds = train_ds.map(lambda x: read_record(x, variables, structured=False))\n",
    "# train_ds = train_ds.map(lambda x, y, z, _: (x, threshold(y, 't')[0]))\n",
    "# train_ds = train_ds.batch(1).prefetch(2)\n",
    "\n",
    "# # train model\n",
    "# model.fit(train_ds, batch_size=1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-GPU training\n",
    "\n",
    "Distributed training can be performed by transforming the dataset to address variable image sizes.\n",
    "\n",
    "When creating a model, setting `ragged=True` indicates to the model to expect a ragged dataset where feature tensors with possibly variable dimensions are batched.\n",
    "\n",
    "The function `mil.io.transforms.parallel_dataset` performs the necessary transformation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a MirroredStrategy for multi-GPU training\n",
    "# strategy = tf.distribute.MirroredStrategy()  \n",
    "\n",
    "# # create and compile the model and metrics in the strategy scopes\n",
    "# with strategy.scope():\n",
    "    \n",
    "#     # create a model with ragged inputs\n",
    "#     model = attention_flat(D, ragged=True) \n",
    "    \n",
    "#     # metrics will be aggregated across gpus\n",
    "#     metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
    "#             tf.keras.metrics.AUC(curve='ROC'),\n",
    "#             Balanced(threshold=0.5),\n",
    "#             F1(threshold=0.5),\n",
    "#             Mcc(threshold=0.5),\n",
    "#             Sensitivity(threshold=0.5),\n",
    "#             Specificity(threshold=0.5)]\n",
    "\n",
    "#     # compile the model\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "#                 loss={'softmax': tf.keras.losses.BinaryCrossentropy()},\n",
    "#                 metrics={'softmax': metrics})\n",
    "\n",
    "\n",
    "# #define label function for training dataset\n",
    "# def threshold(value, key='t', cond=lambda x: x>=2.0):\n",
    "#     return tf.one_hot(tf.cast(cond(value[key]), tf.int32), depth=2)\n",
    "\n",
    "# # build dataset and train\n",
    "# train_ds = tf.data.TFRecordDataset(files, num_parallel_reads=strategy.num_replicas_in_sync).shuffle(len(files))\n",
    "# train_ds = train_ds.map(lambda x: read_record(x, variables, structured=False))\n",
    "# train_ds = train_ds.map(lambda x, y, z, _: (x, threshold(y, 't')[0]))\n",
    "# train_ds = parallel_dataset(train_ds, \n",
    "#                             D, \n",
    "#                             strategy.num_replicas_in_sync,\n",
    "#                             structured=False)\n",
    "# train_ds = train_ds.prefetch(2)\n",
    "\n",
    "# # train model\n",
    "# model.fit(train_ds, batch_size=strategy.num_replicas_in_sync, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Hyperparameter tuning for attention_flat model can be performed by creating an object of class `attention_flat_tune` and setting the number of trials `trial_num` and number of allocated GPUs/CPUs per `trial resources_per_trial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object of attention_flat_tune\n",
    "tuner = attention_flat_tune(trial_num=20, resources_per_trial=1)\n",
    "config = tuner.get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify and set tuning config\n",
    "config[\"dataset_params\"] = {\"files\": files, \"variables\": variables, \"structured\": False}\n",
    "config[\"training_params\"][\"D\"] = D\n",
    "tuner.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tuner to look for the best hyperparameters\n",
    "attention_flat_best_params = tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build attention_flat using the best hyperparameters\n",
    "model = attention_flat(D, config=attention_flat_best_params, ragged=False) \n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss={'softmax': tf.keras.losses.BinaryCrossentropy()},\n",
    "              metrics={'softmax': metrics})\n",
    "\n",
    "# build dataset and train\n",
    "train_ds = tf.data.TFRecordDataset(files, num_parallel_reads=4).shuffle(len(files))\n",
    "train_ds = train_ds.map(lambda x: read_record(x, variables, structured=False))\n",
    "train_ds = train_ds.map(lambda x, y, z, _: (x, threshold(y, 't')[0]))\n",
    "train_ds = train_ds.batch(1).prefetch(2)\n",
    "\n",
    "# train model\n",
    "model.fit(train_ds, batch_size=1, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a440aeac0c89e2af7569e0aa53b64434c4b69eb6285e2b0d174d9bca190d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
